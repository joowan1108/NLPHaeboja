{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPvTiLfIBp6d+zHWx+l8Jw5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"wNld-tlhbHhj","executionInfo":{"status":"ok","timestamp":1708078728557,"user_tz":-540,"elapsed":3610,"user":{"displayName":"주완채","userId":"14152143105854180609"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn"]},{"cell_type":"code","source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","# for reproducibility\n","torch.manual_seed(777)\n","if device == 'cuda':\n","    torch.cuda.manual_seed_all(777)"],"metadata":{"id":"0bJC7KvIb1MC","executionInfo":{"status":"ok","timestamp":1708079456579,"user_tz":-540,"elapsed":626,"user":{"displayName":"주완채","userId":"14152143105854180609"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["X = torch.FloatTensor([[0,0], [0,1], [1,0], [1,1]]).to(device)\n","Y = torch.FloatTensor([[0],[1],[1],[0]]).to(device)\n"],"metadata":{"id":"ug7G_zmFb1so","executionInfo":{"status":"ok","timestamp":1708079537174,"user_tz":-540,"elapsed":492,"user":{"displayName":"주완채","userId":"14152143105854180609"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"7LAhkfuOeDBp","executionInfo":{"status":"ok","timestamp":1708079539068,"user_tz":-540,"elapsed":4,"user":{"displayName":"주완채","userId":"14152143105854180609"}},"outputId":"958da8a2-b81e-49ee-cf0f-ea546ad34295"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'cuda'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","source":["input dim = 4x2\n","\n","layer는 3개이고 hidden layer의 output을 10개로 할 것이다.\n","\n","h1, h2, h3는 따라서 차원이 10이다."],"metadata":{"id":"tXYPgX-_cLRD"}},{"cell_type":"code","source":["model = nn.Sequential(\n","    nn.Linear(2,10, bias=True),\n","    nn.Sigmoid(), #h1 값 나옴\n","    nn.Linear(10,10, bias=True),\n","    nn.Sigmoid(), #h2\n","    nn.Linear(10,10, bias=True),\n","    nn.Sigmoid(), #h3\n","    nn.Linear(10,1, bias=True),\n","    nn.Sigmoid() #output\n",").to(device)"],"metadata":{"id":"3vBtGMKpcBoS","executionInfo":{"status":"ok","timestamp":1708079540936,"user_tz":-540,"elapsed":2,"user":{"displayName":"주완채","userId":"14152143105854180609"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["#이제 error를 계산할 cost function과 최적화 방법(gradient descent)를 설정\n","criterion = torch.nn.BCELoss().to(device)\n","optimizer = torch.optim.SGD(model.parameters(), lr=1)"],"metadata":{"id":"vZmJYVjCdERT","executionInfo":{"status":"ok","timestamp":1708079542830,"user_tz":-540,"elapsed":2,"user":{"displayName":"주완채","userId":"14152143105854180609"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["for epoch in range(10001):\n","  hypothesis = model(X)\n","\n","  optimizer.zero_grad()\n","  cost = criterion(hypothesis, Y)\n","  cost.backward()\n","  optimizer.step()\n","\n","  if epoch % 100 ==0:\n","    print(\"epoch: {} Cost: {}\".format(epoch, cost.item()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XU0gKSoRdVz7","executionInfo":{"status":"ok","timestamp":1708079557995,"user_tz":-540,"elapsed":13205,"user":{"displayName":"주완채","userId":"14152143105854180609"}},"outputId":"97ca9793-5111-4849-d1da-ba449f3f6d85"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch: 0 Cost: 0.7408947944641113\n","epoch: 100 Cost: 0.6931389570236206\n","epoch: 200 Cost: 0.6931374073028564\n","epoch: 300 Cost: 0.6931357383728027\n","epoch: 400 Cost: 0.6931341886520386\n","epoch: 500 Cost: 0.6931324601173401\n","epoch: 600 Cost: 0.693130612373352\n","epoch: 700 Cost: 0.6931287050247192\n","epoch: 800 Cost: 0.6931267380714417\n","epoch: 900 Cost: 0.6931246519088745\n","epoch: 1000 Cost: 0.6931224465370178\n","epoch: 1100 Cost: 0.693120002746582\n","epoch: 1200 Cost: 0.6931174993515015\n","epoch: 1300 Cost: 0.6931147575378418\n","epoch: 1400 Cost: 0.693111777305603\n","epoch: 1500 Cost: 0.6931086182594299\n","epoch: 1600 Cost: 0.693105161190033\n","epoch: 1700 Cost: 0.6931012868881226\n","epoch: 1800 Cost: 0.6930969953536987\n","epoch: 1900 Cost: 0.6930923461914062\n","epoch: 2000 Cost: 0.693087100982666\n","epoch: 2100 Cost: 0.693081259727478\n","epoch: 2200 Cost: 0.693074643611908\n","epoch: 2300 Cost: 0.693067193031311\n","epoch: 2400 Cost: 0.6930586099624634\n","epoch: 2500 Cost: 0.6930487155914307\n","epoch: 2600 Cost: 0.693037211894989\n","epoch: 2700 Cost: 0.6930238008499146\n","epoch: 2800 Cost: 0.6930078268051147\n","epoch: 2900 Cost: 0.6929886937141418\n","epoch: 3000 Cost: 0.6929654479026794\n","epoch: 3100 Cost: 0.6929367780685425\n","epoch: 3200 Cost: 0.6929006576538086\n","epoch: 3300 Cost: 0.6928542852401733\n","epoch: 3400 Cost: 0.6927931904792786\n","epoch: 3500 Cost: 0.692710280418396\n","epoch: 3600 Cost: 0.692592978477478\n","epoch: 3700 Cost: 0.6924186944961548\n","epoch: 3800 Cost: 0.6921423673629761\n","epoch: 3900 Cost: 0.6916618347167969\n","epoch: 4000 Cost: 0.6907041072845459\n","epoch: 4100 Cost: 0.6883158087730408\n","epoch: 4200 Cost: 0.6790611743927002\n","epoch: 4300 Cost: 0.5542722344398499\n","epoch: 4400 Cost: 0.02972596324980259\n","epoch: 4500 Cost: 0.007717072032392025\n","epoch: 4600 Cost: 0.004087917506694794\n","epoch: 4700 Cost: 0.0027092061936855316\n","epoch: 4800 Cost: 0.0020012895110994577\n","epoch: 4900 Cost: 0.0015756789362058043\n","epoch: 5000 Cost: 0.0012935677077621222\n","epoch: 5100 Cost: 0.0010938148479908705\n","epoch: 5200 Cost: 0.0009454327519051731\n","epoch: 5300 Cost: 0.0008311194833368063\n","epoch: 5400 Cost: 0.0007404994103126228\n","epoch: 5500 Cost: 0.0006670353468507528\n","epoch: 5600 Cost: 0.000606327666901052\n","epoch: 5700 Cost: 0.0005553581286221743\n","epoch: 5800 Cost: 0.0005120142013765872\n","epoch: 5900 Cost: 0.0004747192142531276\n","epoch: 6000 Cost: 0.0004422780475579202\n","epoch: 6100 Cost: 0.00041384814539924264\n","epoch: 6200 Cost: 0.00038875179598107934\n","epoch: 6300 Cost: 0.0003664066316559911\n","epoch: 6400 Cost: 0.0003463983302935958\n","epoch: 6500 Cost: 0.0003283727273810655\n","epoch: 6600 Cost: 0.000312103918986395\n","epoch: 6700 Cost: 0.0002973015944007784\n","epoch: 6800 Cost: 0.00028376199770718813\n","epoch: 6900 Cost: 0.00027139601297676563\n","epoch: 7000 Cost: 0.0002600126899778843\n","epoch: 7100 Cost: 0.00024951400700956583\n","epoch: 7200 Cost: 0.00023985025472939014\n","epoch: 7300 Cost: 0.00023083144333213568\n","epoch: 7400 Cost: 0.00022245198488235474\n","epoch: 7500 Cost: 0.00021465009194798768\n","epoch: 7600 Cost: 0.00020734049030579627\n","epoch: 7700 Cost: 0.00020052804029546678\n","epoch: 7800 Cost: 0.00019413369591347873\n","epoch: 7900 Cost: 0.00018807733431458473\n","epoch: 8000 Cost: 0.00018240348435938358\n","epoch: 8100 Cost: 0.00017705446225591004\n","epoch: 8200 Cost: 0.00017201514856424183\n","epoch: 8300 Cost: 0.00016722890723031014\n","epoch: 8400 Cost: 0.00016270102059934288\n","epoch: 8500 Cost: 0.00015842309221625328\n","epoch: 8600 Cost: 0.0001543103571748361\n","epoch: 8700 Cost: 0.00015044442261569202\n","epoch: 8800 Cost: 0.0001467299007344991\n","epoch: 8900 Cost: 0.00014318949251901358\n","epoch: 9000 Cost: 0.00013981857046019286\n","epoch: 9100 Cost: 0.00013658107491210103\n","epoch: 9200 Cost: 0.0001335328706772998\n","epoch: 9300 Cost: 0.00013057909382041544\n","epoch: 9400 Cost: 0.00012777623487636447\n","epoch: 9500 Cost: 0.00012506070197559893\n","epoch: 9600 Cost: 0.00012242898810654879\n","epoch: 9700 Cost: 0.0001199373509734869\n","epoch: 9800 Cost: 0.00011755309969885275\n","epoch: 9900 Cost: 0.00011521459236973897\n","epoch: 10000 Cost: 0.00011303801875328645\n"]}]},{"cell_type":"markdown","source":["#예측값 확인하기\n"],"metadata":{"id":"d7tDFPzFef7X"}},{"cell_type":"code","source":["with torch.no_grad():\n","  hypothesis = model(X)\n","  predicted = (hypothesis > 0.5).float()\n","  accuracy = (predicted == Y).float().mean()\n","  print('모델의 출력값(Hypothesis): ', hypothesis.detach().cpu().numpy())\n","  print('모델의 예측값(Predicted): ', predicted.detach().cpu().numpy())\n","  print('실제값(Y): ', Y.cpu().numpy())\n","  print('정확도(Accuracy): ', accuracy.item())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a4JRmIcqedt0","executionInfo":{"status":"ok","timestamp":1708079654643,"user_tz":-540,"elapsed":576,"user":{"displayName":"주완채","userId":"14152143105854180609"}},"outputId":"2423310e-113e-4925-b8e0-0530abd864b6"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["모델의 출력값(Hypothesis):  [[6.8911293e-05]\n"," [9.9988151e-01]\n"," [9.9989223e-01]\n"," [1.5679191e-04]]\n","모델의 예측값(Predicted):  [[0.]\n"," [1.]\n"," [1.]\n"," [0.]]\n","실제값(Y):  [[0.]\n"," [1.]\n"," [1.]\n"," [0.]]\n","정확도(Accuracy):  1.0\n"]}]}]}