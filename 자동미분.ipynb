{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMgWzSNuekzhfkkguYWd0Tm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Autograd: 자동 미분\n","하는 이유: gradient descent를 통해 비용이 최소화되는 방향을 찾을 때, 이를 직접 코딩하는 것을 방지하기 위해 requires_grad=True와 backward()를 사용한다."],"metadata":{"id":"zG1pFx0DJorr"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cJxqOTkXJoD3","executionInfo":{"status":"ok","timestamp":1707822686471,"user_tz":-540,"elapsed":5159,"user":{"displayName":"주완채","userId":"14152143105854180609"}},"outputId":"6925c24a-aacb-4889-9b04-01db46135afd"},"outputs":[{"output_type":"stream","name":"stdout","text":["미분값: 8.0\n"]}],"source":["import torch\n","\n","w=torch.tensor(2.0, requires_grad=True)\n","y=w**2\n","z = 2*y + 5\n","\n","#requires_grad=True가 설정된 변수에 대해 미분한 값을 계산한다.\n","z.backward()\n","\n","print(\"미분값: {}\".format(w.grad))\n"]}]}